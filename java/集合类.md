# 集合类总结

## 源码分析

### ArrayList

#### 1.初始化

​	底层使用数组实现，初始默认大小为10，最大存储上限为Integer.MAX_VALUE-8，数组默认不序列化。

​	记录修改次数modCount，在使用迭代器遍历的时候，用来检查列表中的元素是否发生结构性变化。每次当使用add()、remove()等方法的时候modCount就会+1。

```java
// 初始数组大小
private static final int DEFAULT_CAPACITY = 10;

// 底层存储使用数组，声明数组默认不会被序列化，重写了 writeObject() 和 readObject() 来控制只序列化数组中有元素填充那部分内容
transient Object[] elementData; // non-private to simplify nested class access

// 记录修改次数
protected transient int modCount = 0;

// 数组最大上限值为Integer.MAX_VALUE-8
private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;
```

####  2.保障

   检查数组越界，数组最小大小不会小于10，增加修改次数值，如果数组不够大，那么扩容。

```java
// 判断数组是否越界，保障数组最小不会小于minCapacity，如果minCaoacity超过了最大值，那么就报错
private void ensureCapacityInternal(int minCapacity) {
        ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));
    }
// 保证数组最小不会少于10
private static int calculateCapacity(Object[] elementData, int minCapacity) {
        if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
            return Math.max(DEFAULT_CAPACITY, minCapacity);
        }
        return minCapacity;
    }
// 增加修改次数值，如果数组不够大，那么扩容
private void ensureExplicitCapacity(int minCapacity) {
    modCount++;
    // overflow-conscious code
    if (minCapacity - elementData.length > 0)
        grow(minCapacity);
}
```

#### 3.扩容

​	可以指定最小扩容大小，但不会小于1.5倍。不会超过最大上限。

​	扩容操作需要调用 `Arrays.copyOf()` 把原数组整个复制到新数组中，这个操作代价很高。

```java
// 扩容
private void grow(int minCapacity) {		// 可指定最小扩容后数组大小，但是不会小于1.5倍原来大小
        // overflow-conscious code
        int oldCapacity = elementData.length;
        int newCapacity = oldCapacity + (oldCapacity >> 1);			// 扩大为原来的1.5倍
        if (newCapacity - minCapacity < 0)
            newCapacity = minCapacity;
        if (newCapacity - MAX_ARRAY_SIZE > 0)			// 保证扩容后大小不超过最大上限MAX_ARRAY_SIZE
            newCapacity = hugeCapacity(minCapacity);
        // minCapacity is usually close to size, so this is a win:
        elementData = Arrays.copyOf(elementData, newCapacity);
    }
```

#### 4.缩容

   trimToSize()作用只是去掉预留元素位置。如果数组大小大于数组实际使用长度，那么就会收缩数组大小。

```java
// 如果size大于length那么就缩容，采用Arrays.copyOf复制，比较费时间
public void trimToSize() {
        modCount++;
        if (size < elementData.length) {
            elementData = (size == 0)
              ? EMPTY_ELEMENTDATA
              : Arrays.copyOf(elementData, size);		// 采用Arrays.copyOf复制一个新的数组
        }
    }
```

#### 5.删除

   有两种remove方法，一种是根据index位置删除，一种是比较元素是否equals删除，注意不是比较引用是否相同。

​	前者将index后的所有元素向前移动一位，采用System.arrayCopy移动，很费时间。后者则是需要从头遍历整个元素数组，所以都是花费线性时间，总体后者更费时间。

```java
public E remove(int index) {
    rangeCheck(index);		// 检查index是否在范围内

    modCount++;				// 修改改动次数值
    E oldValue = elementData(index);

    int numMoved = size - index - 1;
    if (numMoved > 0)
        System.arraycopy(elementData, index+1, elementData, index,
                         numMoved);
    elementData[--size] = null; // clear to let GC do its work

    return oldValue;
}

public boolean remove(Object o) {
    if (o == null) {
        for (int index = 0; index < size; index++)
            if (elementData[index] == null) {
                // 将index后面的元素向前移动一位
                fastRemove(index);
                return true;
            }
    } else {
        for (int index = 0; index < size; index++)
            if (o.equals(elementData[index])) {
                fastRemove(index);
                return true;
            }
    }
    return false;
}
```

#### 6.Fail-Fast

   fail-fast 机制在遍历一个集合时，当集合结构被修改，会抛出 ConcurrentModificationException。

   fail-fast 会在以下两种情况下抛出 ConcurrentModificationException

   (1) 单线程

   - 集合被创建后，在遍历它的过程中修改了结构。
   - 注意 remove() 方法会让 expectModcount 和 modCount 相等，所以是不会抛出这个异常。

   (2) 多线程

   - 当一个线程在遍历这个集合，而另一个线程对这个集合的结构进行了修改。

   modCount 用来记录 ArrayList 结构发生变化的次数。结构发生变化是指**添加**或者**删除**至少一个元素的所有操作，或者是调整内部数组的大小，仅仅只是设置元素的值不算结构发生变化。

   在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，如果改变了需要抛出 Concurrent Modification Exception。



使用Array.asList()产生的List并不是java.util.ArrayList()，不可以改动大小，可以修改值。

```java
List<String> list = Arrays.asList("a","b");
list.add("c");
```

### Vector

- Vector 是同步的，因此开销就比 ArrayList 要大，访问速度更慢。
- Vector 每次扩容请求其大小的 2 倍空间，而 ArrayList 是 1.5 倍。

####  Vector 替代方案

synchronizedList

为了获得线程安全的 ArrayList，可以使用 `Collections.synchronizedList();` 得到一个线程安全的 ArrayList。

CopyOnWriteArrayList

CopyOnWrite 容器即写时复制的容器。通俗的理解是**当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行 Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器**。

CopyOnWrite 容器有很多优点，但是同时也存在两个问题，即内存占用问题和数据一致性问题。所以在开发的时候需要注意一下。

### LinkedList

​	LinkedList 底层是基于双向链表实现的，LinkedList 同时实现了 List 接口和 Deque 接口，既可以看作一个顺序容器，又可以看作一个队列（Queue），同时又可以看作一个栈（Stack）。

基于双向链表实现，内部使用 Node 来存储链表节点信息。

实现方式决定了所有跟下标相关的操作都是线性时间，而在首段或者末尾删除元素只需要常数时间。

```java
private static class Node<E> {
    E item;
    Node<E> next;
    Node<E> prev;

    Node(Node<E> prev, E element, Node<E> next) {
        this.item = element;
        this.next = next;
        this.prev = prev;
    }
}
```

头结点指针和尾节点指针。

```java
transient Node<E> last;
transient Node<E> first;
```

#### add()

```java
// 在末尾加入元素
public boolean add(E e) {
    linkLast(e);
    return true;
}
// 检查index位置是不是在链表范围或是末尾
private boolean isPositionIndex(int index) {
        return index >= 0 && index <= size;
}
// 抛出异常处理
private void checkPositionIndex(int index) {
        if (!isPositionIndex(index))
            throw new IndexOutOfBoundsException(outOfBoundsMsg(index));
}
// 在index位置原节点前面插入新元素
public void add(int index, E element) {
        checkPositionIndex(index);

        if (index == size)
            linkLast(element);
        else
            linkBefore(element, node(index));
}
// 根据index大小决定从头还是从尾找，找到并返回index位置的节点指针
Node<E> node(int index) {
        if (index < (size >> 1)) {
            Node<E> x = first;
            for (int i = 0; i < index; i++)
                x = x.next;
            return x;
        } else {
            Node<E> x = last;
            for (int i = size - 1; i > index; i--)
                x = x.prev;
            return x;
        }
}
// 在succ节点前面插入元素e
void linkBefore(E e, Node<E> succ) {
    // assert succ != null;
    final Node<E> pred = succ.prev;
    final Node<E> newNode = new Node<>(pred, e, succ);
    succ.prev = newNode;
    if (pred == null)
        first = newNode;
    else
        pred.next = newNode;
    size++;
    modCount++;
}
```

#### remove()

```java
// 通过比较删除equals相等的节点，总是从first指针开始遍历，null可以处理
public boolean remove(Object o) {
    if (o == null) {
        for (Node<E> x = first; x != null; x = x.next) {
            if (x.item == null) {
                // 将x节点从链上除去
                unlink(x);
                return true;
            }
        }
    } else {
        for (Node<E> x = first; x != null; x = x.next) {
            if (o.equals(x.item)) {
                unlink(x);
                return true;
            }
        }
    }
    return false;
}
```

#### get()

每次遍历不会超过链表一半的长度

```java
public E get(int index) {
    checkElementIndex(index);
    // 每次遍历不会超过链表一半的长度
    return node(index).item;
}
```

#### set()

和add()方法的不同就是它是替换，而不是插入

```java
public E set(int index, E element) {
    checkElementIndex(index);
    Node<E> x = node(index);
    E oldVal = x.item;
    x.item = element;
    return oldVal;
}
```

#### 和ArrayList比较

ArrayList是有明确容量上限的`Integer.MAX_VALUE-8`，而LinkedList没有这样的明确上限。

在需要对索引处理的方面，LinkedList的效率不高，而ArrayList可以随机访存。

在处理链表头尾的时候，LinkedList是常数时间。

### HashMap

最大容量：1<<30;

初始容量：16；

当链表长度达到8的时候会触发链表转化成为红黑树存储结构。

在转变成树之前，还会有一次判断，只有键值对（table的容量）数量大于*64* 才会发生转换。

loadFactor代表负载因子，当Node哈希桶数组长度确定时，负载因子决定了负荷量，默认为0.75，代表负载达到75%以上时，table数组将会扩容，每次扩容为原来的两倍。

```java
// 初始容量16
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16
// 最大容量
static final int MAXIMUM_CAPACITY = 1 << 30;
// 链表转红黑树的容量阈值
static final int TREEIFY_THRESHOLD = 8;
// 红黑树收缩回链表的容量阈值
static final int UNTREEIFY_THRESHOLD = 6;
// 链表转换树之前，只有键值对数量大约这个值时，才会发生转换
static final int MIN_TREEIFY_CAPACITY = 64;

int threshold;             // 所能容纳的key-value对极限 
final float loadFactor;    // 负载因子
int modCount;  
int size; 				 // 整个Map的所有键值对总数量
```



#### 存储结构

在 1.7 之前 JDK 采用「拉链法」来存储数据，即数组和链表结合的方式，在 JDK1.8 之后，在链表新增节点导致链表长度超过 `TREEIFY_THRESHOLD = 8` 的时候，就会在添加元素的同时将原来的单链表转化为红黑树。

从结构实现来讲，HashMap 是数组+链表+红黑树（JDK1.8增加了红黑树部分）实现的。

内部类：哈希桶数组Node[]  table，本质是就是一个映射（键值对）。

```java
static class Node<K,V> implements Map.Entry<K,V> {
    final int hash;
    final K key;
    V value;
    Node<K,V> next;

    Node(int hash, K key, V value, Node<K,V> next) {
        this.hash = hash;
        this.key = key;
        this.value = value;
        this.next = next;
    }

    public final K getKey()        { return key; }
    public final V getValue()      { return value; }
    public final String toString() { return key + "=" + value; }

    public final int hashCode() {
        return Objects.hashCode(key) ^ Objects.hashCode(value);
    }

    public final V setValue(V newValue) {
        V oldValue = value;
        value = newValue;
        return oldValue;
    }
// 键值都相等的才满足equals
    public final boolean equals(Object o) {
        if (o == this)
            return true;
        if (o instanceof Map.Entry) {
            Map.Entry<?,?> e = (Map.Entry<?,?>)o;
            if (Objects.equals(key, e.getKey()) &&
                Objects.equals(value, e.getValue()))
                return true;
        }
        return false;
    }
}
```

求hash值

```java
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

#### 哈希桶数组重新定容

​	在扩容的时候，要将原哈希桶中的元素复制到新的哈希桶中，对每一个元素都需要重新计算hash值，根据新的hash值，决定元素插入到新的哈希数组的位置，jdk1.7就是这么干的。

​	但是jdk中的哈希桶的容量一般是2的整数次幂，因此拥有一些特别的特性，新的位置和原有的位置有一定的关系，新位置要么就是在原位置不变，要么就是在原位置再移动旧容量大小的距离。判断的依据是用哈希值和旧容量与运算，如果是0就是位置不变。这是由于对2的整数次幂取余运算的特性导致的。

```java
final Node<K,V>[] resize() {
    Node<K,V>[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap > 0) {
        // 如果旧数组长度已经达到最大值，那么无法扩大数组长度，
        //而是让threshold突破负载因子的上限，达到Integer.MAX_VALUE
        if (oldCap >= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        // 否则让新的容量为原容量的两倍，但不会超过最大上限
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                 oldCap >= DEFAULT_INITIAL_CAPACITY)
            newThr = oldThr << 1; // double threshold
    }
    // 将初始容量设置为阈值（收缩了）
    else if (oldThr > 0) // initial capacity was placed in threshold
        newCap = oldThr;
    // 零初始阈值表示使用默认值，这一般是loadFactor设置错误导致的
    else {               // zero initial threshold signifies using defaults
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    // 调整新阈值
    if (newThr == 0) {
        float ft = (float)newCap * loadFactor;
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                  (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;
    @SuppressWarnings({"rawtypes","unchecked"})
        Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab;
    // 完成旧表到新表的复制
    if (oldTab != null) {
        for (int j = 0; j < oldCap; ++j) {
            Node<K,V> e;
            if ((e = oldTab[j]) != null) {
                // 数组引用设空，让GC清理旧table的元素
                oldTab[j] = null;
                // 首个元素
                if (e.next == null)
                    newTab[e.hash & (newCap - 1)] = e;
                else if (e instanceof TreeNode)
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                else { // preserve order
                    Node<K,V> loHead = null, loTail = null;
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    do {
                        next = e.next;
                        if ((e.hash & oldCap) == 0) {		// 判断在新数组中的位置
                            if (loTail == null)				// 在原位置
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        else {								// 向后移动oldCap个位置
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}
```

#### put()

![img](https://github.com/frank-lam/fullstack-tutorial/raw/master/notes/JavaArchitecture/assets/hashmap-put.png)

####  线程安全性

​	在多线程使用场景中，应该尽量避免使用线程不安全的 HashMap，而使用线程安全的 ConcurrentHashMap。

​	在并发的多线程使用场景中使用 HashMap 可能造成死循环，就是出现环形的链表，在查找不存在的元素时，将会死循环。

#### 小结

- 扩容是一个特别耗性能的操作，所以当程序员在使用 HashMap 的时候，估算 map 的大小，初始化的时候给一个大致的数值，避免 map 进行频繁的扩容。
- 负载因子是可以修改的，也可以大于1，但是建议不要轻易修改，除非情况非常特殊。如果对查找性能要求高，可以调小一些，如果对内存使用比较紧张，可以调大一些。
- HashMap 是线程不安全的，不要在并发的环境中同时操作 HashMap，建议使用 ConcurrentHashMap。
- JDK1.8 引入红黑树大程度优化了 HashMap 的性能。

### ConcurrentHashMap——jdk1.7

​	jdk1.7ConcurrentHashMap 采用了"分段锁"策略，ConcurrentHashMap 的主干是个 Segment 数组。

>  final Segment<K,V>[] segments;

​	Segment 继承了 ReentrantLock，所以它就是一种可重入锁（ReentrantLock)。。在 ConcurrentHashMap，一个 Segment 就是一个子哈希表，Segment 里维护了一个 HashEntry 数组，并发环境下，对于不同 Segment 的数据进行操作是不用考虑锁竞争的。

>  transient volatile HashEntry<K,V>[] table;

​	一个 Segment 维护着一个 HashEntry 数组。

```java
static final class HashEntry<K,V> {
    final int hash;
    final K key;
    volatile V value;
    volatile HashEntry<K,V> next;
}
```

默认的并发级别为 16，也就是说默认创建 16 个 Segment。

>  static final int DEFAULT_CONCURRENCY_LEVEL = 16;

####  size 操作

​	在执行 size 操作时，需要遍历所有 Segment 然后把 count 累计起来。

​	ConcurrentHashMap 在执行 size 操作时先尝试不加锁，如果连续两次不加锁操作得到的结果一致，那么可以认为这个结果是正确的。

#### 同步方式

​	对于读操作，老版本是采用volatile关键字，使用 volatile 时每次写操作都会让所有 CPU 内缓存无效，也有一定开销。

​	jdk1.7使用这种办法：

> Segment<K,V> s = (Segment<K,V>)UNSAFE.getObjectVolatile(segments, u);

​	获取Segment中的HashEntry时也使用了类似方法。



​	对于写操作，并不要求同时获取所有 Segment 的锁，因为那样相当于锁住了整个 Map。它会先获取该 Key-Value 对所在的 Segment 的锁，获取成功后就可以像操作一个普通的 HashMap 一样操作该 Segment，并保证该Segment 的安全性。

​	获取锁时，并不直接使用lock来获取，因为该方法获取锁失败时会挂起（参考可重入锁）。事实上，它使用了自旋锁，如果tryLock获取锁失败，说明锁被其它线程占用，此时通过循环再次以tryLock的方式申请锁。如果在循环过程中该Key所对应的链表头被修改，则重置retry次数。如果retry次数超过一定值，则使用lock方法申请锁。

​	这里使用自旋锁是因为自旋锁的效率比较高，但是它消耗CPU资源比较多，因此在自旋次数超过阈值时切换为互斥锁。

### ConcurrentHashMap——jdk1.8

Java 8为进一步提高并发性，摒弃了分段锁的方案，而是直接使用一个大的数组。同时为了提高哈希碰撞下的寻址性能，Java 8在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为O(N)）转换为红黑树（寻址时间复杂度为O(long(N))）。

#### 同步方式

​	对于put操作，如果Key对应的数组元素为null，则通过CAS操作将其设置为当前值。如果Key对应的数组元素（也即链表表头或者树的根元素）不为null，则对该元素使用synchronized关键字申请锁，然后进行操作。如果该put操作使得当前链表长度超过一定阈值，则将该链表转换为树，从而提高寻址效率。

​	对于读操作，由于数组被volatile关键字修饰，因此不用担心数组的可见性问题。同时每个元素是一个Node实例（Java 7中每个元素是一个HashEntry），它的Key值和hash值都由final修饰，不可变更，无须关心它们被修改后的可见性问题。而其Value及对下一个元素的引用由volatile修饰，可见性也有保障。

#### size操作

​	put方法和remove方法都会通过addCount方法维护Map的size。size方法通过sumCount获取由addCount方法维护的Map的size。

### HashSet

 HashSet 是对 HashMap 的简单包装，对 HashSet 的函数调用都会转换成合适的 HashMap 方法，因此 HashSet 的实现非常简单，只有不到 300 行代码（适配器模式）。

```java
private transient HashMap<E,Object> map;

// Dummy value to associate with an Object in the backing Map
private static final Object PRESENT = new Object();
```

只有两个重要的变量

- map：存放最终的数据
- PRESENT：是所有写入 map 的 `value` 值

#### add操作

```java
public boolean add(E e) {
        return map.put(e, PRESENT)==null;
    }
```

​	比较关键的就是这个 `add()` 方法。 可以看出它是将存放的对象当做了 `HashMap` 的健，`value` 都是相同的 `PRESENT` 。由于 `HashMap` 的 `key` 是不能重复的，所以每当有重复的值写入到 `HashSet` 时，`value` 会被覆盖，但 `key` 不会收到影响，这样就保证了 `HashSet` 中只能存放不重复的元素。



### BlackQueue

阻塞式队列：是一个接口，

# 算法类

## 排序算法

​	List接口中有一个默认实现的方法`sort(Comparator<? super E> c)`，可以为List排序。可以发现源码中实际调用的是Arrays.sort()。

​	可以发现List排序后，采用迭代器遍历加set()方法赋值，所以ArrayList和LinkedList的排序效率是一致的。

​	查看Collections.sort()源码可以发现，其实也是调用的List.sort()，因此可以知道这几种常用的排序方法其实都是在调用Array.sort()方法。只不过集合先转成Object数组，排好序，再用set方法赋值回去。

```java
// List接口中的排序方法
default void sort(Comparator<? super E> c) {
        Object[] a = this.toArray();
        Arrays.sort(a, (Comparator) c);
        ListIterator<E> i = this.listIterator();
        for (Object e : a) {
            i.next();
            i.set((E) e);
        }
    }

// Arrays中的排序方法
 public static <T> void sort(T[] a, Comparator<? super T> c) {
     if (c == null) {
         sort(a);
     } else {
         if (LegacyMergeSort.userRequested)
             legacyMergeSort(a, c);
         else
             TimSort.sort(a, 0, a.length, c, null, 0, 0);
     }
 }
```



​	Arrays.sort()根据设置选择不同的排序方法。

​	（1）一种是legacyMergeSort()，也就是归并排序，需要注意的是在二分到数组大小小于7时，使用插入排序。

```java

// 归并排序
private static <T> void legacyMergeSort(T[] a, Comparator<? super T> c) {
        T[] aux = a.clone();
        if (c==null)
            mergeSort(aux, a, 0, a.length, 0);
        else
            mergeSort(aux, a, 0, a.length, 0, c);
}
// 使用插入排序的最大值
private static final int INSERTIONSORT_THRESHOLD = 7;

private static void mergeSort(Object[] src, Object[] dest, int low, int high, int off) {
    int length = high - low;
    // 如果数组长度小于7，就使用插入排序
    if (length < INSERTIONSORT_THRESHOLD) {
        for (int i=low; i<high; i++)
            for (int j=i; j>low &&
                     ((Comparable) dest[j-1]).compareTo(dest[j])>0; j--)
                swap(dest, j, j-1);
        return;
    }

    // 递归二分下去，注意这里的dest和和src互换了，因此回溯后有序的将是src数组
    // 而方法自身保证dest数组有序，src是辅助
    int destLow  = low;
    int destHigh = high;
    low  += off;
    high += off;
    int mid = (low + high) >>> 1;
    mergeSort(dest, src, low, mid, -off);
    mergeSort(dest, src, mid, high, -off);

    // 如果列表已经排序，只需从src复制到dest。
    // 这是一种优化，可以使排序接近有序的列表更快。
    // 因为如果左半部分最大值小于右半部分最小值，那么两个部分的整合就是有序的，无需再归并
    if (((Comparable)src[mid-1]).compareTo(src[mid]) <= 0) {
        System.arraycopy(src, low, dest, destLow, length);
        return;
    }

    // 对两部分进行归并，归并后存入dest
    for(int i = destLow, p = low, q = mid; i < destHigh; i++) {
        if (q >= high || p < mid && ((Comparable)src[p]).compareTo(src[q])<=0)
            dest[i] = src[p++];
        else
            dest[i] = src[q++];
    }
}
```

（2）第二种使用TimSort.sort()排序

​	由于这是一种有些复杂的工业级排序算法，先暂且不深入研究。

- 元素少于32个的时候是二分插入排序，这不是重点

​	countRunAndMakeAscending()作用是：找出最大的递增或者递减的个数，如果递减，则此段数组严格反一下方向。

​	binarySort()：二分查找位置，进行插入排序。根据移动的个数使用不同的移动方法。

- 重点是元素多于32个时

​	先算出一个合适的大小，在将输入按其升序和降序特点进行了分区。排序的输入的单位不是一个个单独的数字，而是一个个的块-分区。其中每一个分区叫一个run。

## Comparator

Arrays.sort()可以给所有的数组排序，第二个参数可以传入一个继承自Comparator的对象。

(1) 匿名类

```java
Arrays.sort(test, new Comparator<Test>() {
            @Override
            public int compare(Test o1, Test o2) {
                return Integer.valueOf(o1.getValue()).compareTo(Integer.valueOf(o2.getValue()));
            }
        });
```

(2) lambda表达式



```java

Arrays.sort(test, (o1, o2)->Integer.valueOf(o1.getValue()).compareTo(Integer.valueOf(o2.getValue())));
```

(3) Comparator.comparing()

comparing 方法接收一个 Function 函数式接口 ，通过一个 lambda 表达式传入。

这有一个lambda的新知识，类名::方法名 代表着一个实现Function接口的类!

```java
Arrays.sort(test, Comparator.comparing(Test::getValue));
Arrays.sort(test, Comparator.comparing(e -> e.getValue()));
```

comparing()方法还有一个重载方法。

`public static <T, U> Comparator<T> comparing(Function<? super T, ? extends U> keyExtractor, Comparator<? super U> keyComparator)`

这个方法两个参数，第一个参数依然是接收一个Function()，第二个是接收一个比较器,比较的是Function的返回值。

```java
Arrays.sort(test, Comparator.comparing(Test::getValue, (o1,o2)-> o2.compareTo(o1)));
```





